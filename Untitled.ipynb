{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "Y = iris.target\n",
    "\n",
    "logreg = LogisticRegression(C=1e5)\n",
    "logreg.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import sys,os\n",
    "\n",
    "import numpy as np\n",
    "import six\n",
    "import pickle\n",
    "import scipy\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import optimizers\n",
    "from chainer import serializers\n",
    "from tqdm import tqdm\n",
    "import scipy.stats as ss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "######################################################################################\n",
    "# 誤差のプロット関数。自動的に保存するので上書きされたくない時は名前を変える\n",
    "\n",
    "def acc(train_acc, test_acc, savename='result_acc.pdf'):\n",
    "    ep = np.arange(len(train_acc)) + 1\n",
    "\n",
    "    plt.plot(ep, train_acc, color=\"blue\", linewidth=1, linestyle=\"-\", label=\"Train\")\n",
    "    plt.plot(ep, test_acc, color=\"red\",  linewidth=1, linestyle=\"-\", label=\"Test\")\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(savename)\n",
    "    \n",
    "\n",
    "    \n",
    "def loss(train_loss, test_loss, savename='result_loss.pdf'):\n",
    "    ep = np.arange(len(train_loss)) + 1\n",
    "\n",
    "    plt.plot(ep, train_loss, color=\"blue\", linewidth=1, linestyle=\"-\", label=\"Train\")\n",
    "    plt.plot(ep, test_loss, color=\"red\",  linewidth=1, linestyle=\"-\", label=\"Test\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.ylabel(\"loss\")\n",
    "\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig(savename)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "class NN(object):\n",
    "\n",
    "    def loadModel(self, modelName):\n",
    "        print('Load model')\n",
    "        serializers.load_hdf5(modelName, self.model)\n",
    "        print('Load optimizer state')\n",
    "        serializers.load_hdf5(modelName[:-5] + 'state', self.optimizer)\n",
    "\n",
    "\n",
    "    def initializeModel(self, Model, train_X, n_units1, n_units2, optimizerAlgorithm):\n",
    "        print(\"prepare initialized model!\")\n",
    "        print(train_X[0])\n",
    "        self.model = Model(len(train_X[0]), n_units1, n_units2, 1)\n",
    "        self.initializeOptimizer(optimizerAlgorithm)\n",
    "\n",
    "    def initializeOptimizer(self, optimizerAlgorithm):\n",
    "        if optimizerAlgorithm == \"Adam\":\n",
    "            self.optimizer = optimizers.Adam(alpha=0.0001)\n",
    "        elif optimizerAlgorithm == \"AdaGrad\":\n",
    "            self.optimizer = optimizers.AdaGrad()\n",
    "        elif optimizerAlgorithm == \"SGD\":\n",
    "            self.optimizer = optimizers.MomentumSGD()\n",
    "        else:\n",
    "            raise ValueError('could not find %s in optimizers {\"Adam\", \"AdaGrad\", \"SGD\"}' % (optimizerAlgorithm))\n",
    "        self.optimizer.setup(self.model)\n",
    "\n",
    "    def saveModels(self, savemodelName):\n",
    "        print('save the model')\n",
    "        serializers.save_hdf5(savemodelName, self.model) \n",
    "        print('save the optimizer')\n",
    "        serializers.save_hdf5(savemodelName[:-5]+ 'state', self.optimizer)  \n",
    "\n",
    "    def splitData(self, fit_X, fit_y, tv_ratio):\n",
    "        print('load dataset')\n",
    "        perm = np.random.permutation(len(fit_X))\n",
    "        N_train = int(np.floor(len(fit_X) * tv_ratio))\n",
    "        train_X, validate_X = np.split(fit_X[perm].astype(np.float32),   [N_train])\n",
    "        train_y, validate_y = np.split(fit_y[perm].astype(np.float32).reshape(len(fit_y), 1), [N_train])\n",
    "        return train_X, train_y, validate_X, validate_y\n",
    "    \n",
    "    def splitData2(self, fit_X, fit_y, tv_ratio):\n",
    "        print('load dataset')\n",
    "        train_X=[]\n",
    "        train_y=[]\n",
    "        validate_X=[] \n",
    "        validate_y=[]\n",
    "        for i in range(0,len(fit_X)):\n",
    "            temp_fit_X=fit_X[i]\n",
    "            tmep_fits_y=fit_y[i]\n",
    "            perm = np.random.permutation(len(temp_fit_X))\n",
    "            N_train = int(np.floor(len(temp_fit_X) * tv_ratio))\n",
    "            temp_train_X, temp_validate_X = np.split(temp_fit_X[perm].astype(np.float32),   [N_train])\n",
    "            temp_train_y, temp_validate_y = np.split(temp_fit_y[perm].astype(np.float32).reshape(len(temp_fit_y), 1), [N_train])\n",
    "            train_X.append(temp_train_X)\n",
    "            train_y.append(temp_train_y)\n",
    "            validate_X.append(temp_validate_X)\n",
    "            validate_y.append(temp_validate_y)\n",
    "        return train_X, train_y, validate_X, validate_y\n",
    "    def predictTargets(self, x_pred, batchsize):\n",
    "        N_pred = len(x_pred)\n",
    "        y_pred = np.zeros(0)\n",
    "        for j in tqdm(six.moves.range(0, N_pred, batchsize)):\n",
    "            x = chainer.Variable(np.asarray(x_pred[j:j + batchsize]), volatile='on')\n",
    "            y_pred = np.append(y_pred, self.model.predict(x))\n",
    "        return y_pred\n",
    "\n",
    "    def predict(self, predict_X):\n",
    "        return self.model.predict(predict_X.astype(np.float32))\n",
    "\n",
    "    # def predict(self, predict_X, batchsize=100):\n",
    "    #     return self.predictTargets(predict_X.astype(np.float32), batchsize)\n",
    "\n",
    "######################################################################################\n",
    "# Define model\n",
    "class Model(chainer.Chain):\n",
    "    \"\"\"\n",
    "    RankNet - Pairwise comparison of ranking.\n",
    "    The original paper:\n",
    "        http://research.microsoft.com/en-us/um/people/cburges/papers/ICML_ranking.pdf\n",
    "    Japanese only:\n",
    "        http://qiita.com/sz_dr/items/0e50120318527a928407\n",
    "    \"\"\"\n",
    "    def __init__(self, n_in, n_units1, n_units2, n_out):\n",
    "        super(Model, self).__init__(\n",
    "            l1=L.Linear(n_in, n_units1),\n",
    "            l2=L.Linear(n_units1, n_units2),\n",
    "            l3=L.Linear(n_units2, n_out),\n",
    "        )\n",
    "    def __call__(self, x_i, x_j, t_i, t_j):\n",
    "        s_i = self.l3(F.relu(self.l2(F.relu(self.l1(x_i)))))\n",
    "        s_j = self.l3(F.relu(self.l2(F.relu(self.l1(x_j)))))\n",
    "        s_diff = s_i - s_j\n",
    "        if t_i.data > t_j.data:\n",
    "            S_ij = 1\n",
    "        elif t_i.data < t_j.data:\n",
    "            S_ij = -1\n",
    "        else:\n",
    "            S_ij = 0\n",
    "        self.loss = (1 - S_ij) * s_diff / 2. + F.log(1 + F.exp(-s_diff))\n",
    "        return self.loss\n",
    "\n",
    "    def predict(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        h = F.relu(self.l3(h2))\n",
    "        return h.data\n",
    "    \n",
    "    def kld(self, vec_true, vec_compare):\n",
    "        ind = vec_true.data * vec_compare.data > 0\n",
    "        ind_var = chainer.Variable(ind)\n",
    "        include_nan = vec_true * F.log(vec_true / vec_compare)\n",
    "        z = chainer.Variable(np.zeros((len(ind), 1), dtype=np.float32))\n",
    "        # return np.nansum(vec_true * np.log(vec_true / vec_compare))\n",
    "        return F.sum(F.where(ind_var, include_nan, z))\n",
    "\n",
    "    def jsd(self, vec_true, vec_compare):\n",
    "        vec_mean = 0.5 * (vec_true + vec_compare)\n",
    "        return 0.5 * self.kld(vec_true, vec_mean) + 0.5 * self.kld(vec_compare, vec_mean)\n",
    "\n",
    "    def topkprob(self, vec, k=5):\n",
    "        vec_sort = np.sort(vec)[-1::-1]\n",
    "        topk = vec_sort[:k]\n",
    "        ary = np.arange(k)\n",
    "        return np.prod([np.exp(topk[i]) / np.sum(np.exp(topk[i:])) for i in ary])\n",
    "\n",
    "    def listwise_cost(self, list_ans, list_pred):\n",
    "        return - np.sum(self.topkprob(list_ans) * np.log(self.topkprob(list_pred)))\n",
    "\n",
    "\n",
    "# Define model\n",
    "class Model(chainer.Chain):\n",
    "    \"\"\"\n",
    "    ListNet - Listwise comparison of ranking.\n",
    "    The original paper:\n",
    "        http://research.microsoft.com/en-us/people/tyliu/listnet.pdf\n",
    "\n",
    "    NOTICE:\n",
    "        The top-k probability is not written.\n",
    "        This is listwise approach with neuralnets, \n",
    "        comparing two arrays by Jensen-Shannon divergence.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n_in, n_units1, n_units2, n_out):\n",
    "        #in our code we have used no of features as n_in and n_out is 1\n",
    "        super(Model, self).__init__(\n",
    "            l1=L.Linear(n_in, n_units1),\n",
    "            l2=L.Linear(n_units1, n_units2),\n",
    "            l3=L.Linear(n_units2, n_out),\n",
    "        )\n",
    "\n",
    "\n",
    "    def __call__(self, x, t):\n",
    "        h1 = self.l1(x)\n",
    "        y = self.l3(F.relu(self.l2(F.relu(self.l1(x)))))\n",
    "        # self.loss = self.listwise_cost(y_data, t_data)\n",
    "        self.loss = self.jsd(t, y)\n",
    "        return self.loss\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "class RankNet(NN):\n",
    "    \"\"\"\n",
    "    RankNet training function.\n",
    "    Usage (Initialize):\n",
    "        RankModel = RankNet()\n",
    "\n",
    "    Usage (Traininng):\n",
    "        Model.fit(X, y)\n",
    "\n",
    "    With options:\n",
    "        Model.fit(X, y, batchsize=100, n_iter=5000, n_units1=512, n_units2=128, tv_ratio=0.95, optimizerAlgorithm=\"Adam\", savefigName=\"result.pdf\", savemodelName=\"RankNet.model\")\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, resumemodelName=None, verbose=True):\n",
    "        self.resumemodelName = resumemodelName\n",
    "        self.train_loss, self.test_loss = [], []\n",
    "        self._verbose = verbose\n",
    "        if resumemodelName is not None:\n",
    "            print(\"load resume model!\")\n",
    "            self.loadModel(resumemodelName)\n",
    "\n",
    "    # Evaluation function of NDCG@100\n",
    "    def ndcg(self, y_true, y_score, k=100):\n",
    "        y_true = y_true.ravel()\n",
    "        y_score = y_score.ravel()\n",
    "        y_true_sorted = sorted(y_true, reverse=True)\n",
    "        ideal_dcg = 0\n",
    "        for i in range(k):\n",
    "            ideal_dcg += (2 ** y_true_sorted[i] - 1.) / np.log2(i + 2)\n",
    "        dcg = 0\n",
    "        argsort_indices = np.argsort(y_score)[::-1]\n",
    "        for i in range(k):\n",
    "            dcg += (2 ** y_true[argsort_indices[i]] - 1.) / np.log2(i + 2)\n",
    "        ndcg = dcg / ideal_dcg\n",
    "        return ndcg\n",
    "\n",
    "    # Training function\n",
    "    def trainModel(self, x_train, y_train, x_test, y_test, n_iter):\n",
    "        sigma = 5.0\n",
    "        loss_step = 100\n",
    "\n",
    "        for step in tqdm(range(n_iter)):\n",
    "            i, j = np.random.randint(len(x_train), size=2)\n",
    "            x_i = chainer.Variable(x_train[i].reshape(1, -1))\n",
    "            x_j = chainer.Variable(x_train[j].reshape(1, -1))\n",
    "            y_i = chainer.Variable(y_train[i])\n",
    "            y_j = chainer.Variable(y_train[j])\n",
    "            self.optimizer.update(self.model, x_i, x_j, y_i, y_j)\n",
    "\n",
    "            if (step + 1) % loss_step == 0:\n",
    "                train_score = self.model.predict(chainer.Variable(x_train))\n",
    "                test_score = self.model.predict(chainer.Variable(x_test))\n",
    "                train_ndcg = self.ndcg(y_train, train_score)\n",
    "                test_ndcg = self.ndcg(y_test, test_score)\n",
    "                self.train_loss.append(train_ndcg)\n",
    "                self.test_loss.append(test_ndcg)\n",
    "                if self._verbose:\n",
    "                    print(\"step: {0}\".format(step + 1))\n",
    "                    print(\"NDCG@100 | train: {0}, test: {1}\".format(train_ndcg, test_ndcg))\n",
    "\n",
    "    def fit(self, fit_X, fit_y, batchsize=100, n_iter=5000, n_units1=512, n_units2=128, tv_ratio=0.95, optimizerAlgorithm=\"Adam\", savefigName=\"result.pdf\", savemodelName=\"RankNet.model\"):\n",
    "        train_X, train_y, validate_X, validate_y = self.splitData(fit_X, fit_y, tv_ratio)\n",
    "        print(\"The number of data, train:\", len(train_X), \"validate:\", len(validate_X))\n",
    "\n",
    "        if self.resumemodelName is None:\n",
    "            print(\"in resume\")\n",
    "            self.initializeModel(Model, train_X, n_units1, n_units2, optimizerAlgorithm)\n",
    "\n",
    "        self.trainModel(train_X, train_y, validate_X, validate_y, n_iter)\n",
    "\n",
    "        acc(self.train_loss, self.test_loss, savename=savefigName)\n",
    "        self.saveModels(savemodelName)\n",
    "\n",
    "################################################################################################\n",
    "## end of file ##\n",
    "################################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankNetModel=RankNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, math\n",
    "from collections import Counter\n",
    "\n",
    "WORD = re.compile(r'\\w+')\n",
    "\n",
    "def text_to_vector(text):\n",
    "     words = WORD.findall(text)\n",
    "     return Counter(words)\n",
    "\n",
    "def cosine(tweet,query):\n",
    "    vec1 = text_to_vector(tweet.lower())\n",
    "    vec2 = text_to_vector(query.lower())\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "#     print(intersection)\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def jaccard(tweet,query):\n",
    "    vec1 = text_to_vector(tweet.lower())\n",
    "    vec2 = text_to_vector(query.lower())\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    union =set(vec1.keys()) | set(vec2.keys())\n",
    "    return len(intersection)/len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text cleaning code\n",
    "import string\n",
    "import re\n",
    " \n",
    "from nltk.corpus import stopwords \n",
    "stopwords_english = stopwords.words('english')\n",
    " \n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    " \n",
    "from nltk.tokenize import TweetTokenizer\n",
    " \n",
    "# Happy Emoticons\n",
    "emoticons_happy = set([\n",
    "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "    '<3'\n",
    "    ])\n",
    " \n",
    "# Sad Emoticons\n",
    "emoticons_sad = set([\n",
    "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('\n",
    "    ])\n",
    " \n",
    "# all emoticons (happy + sad)\n",
    "emoticons = emoticons_happy.union(emoticons_sad)\n",
    "def clean_tweets(tweet):\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    " \n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    " \n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    \n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    " \n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    " \n",
    "    tweets_clean = []    \n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and # remove stopwords\n",
    "              word not in emoticons and # remove emoticons\n",
    "                word not in string.punctuation): # remove punctuation\n",
    "            #tweets_clean.append(word)\n",
    "            stem_word = stemmer.stem(word) # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    " \n",
    "    return tweets_clean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rank', 'Query', 'username', 'created_at', 'verified', 'followers_count', 'friends_count', 'listed_count', 'tweet', 'date', 'Img_present', 'likes', 'comments', 'retweets', 'tags', 'mentions', 'sum_followers_mention', 'url_count']\n",
      "['rank', 'Query', 'username', 'created_at', 'verified', 'followers_count', 'friends_count', 'listed_count', 'tweet', 'date', 'Img_present', 'likes', 'comments', 'retweets', 'tags', 'mentions', 'sum_followers_mention', 'url_count']\n",
      "['rank', 'Query', 'username', 'created_at', 'verified', 'followers_count', 'friends_count', 'listed_count', 'tweet', 'date', 'Img_present', 'likes', 'comments', 'retweets', 'tags', 'mentions', 'sum_followers_mention', 'url_count']\n",
      "['rank', 'Query', 'username', 'created_at', 'verified', 'followers_count', 'friends_count', 'listed_count', 'tweet', 'date', 'Img_present', 'likes', 'comments', 'retweets', 'tags', 'mentions', 'sum_followers_mention', 'url_count']\n",
      "['rank', 'Query', 'username', 'created_at', 'verified', 'followers_count', 'friends_count', 'listed_count', 'tweet', 'date', 'Img_present', 'likes', 'comments', 'retweets', 'tags', 'mentions', 'sum_followers_mention', 'url_count']\n"
     ]
    }
   ],
   "source": [
    "# encoding: utf-8 \n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timezone\n",
    "queries=['INDvAUS','narendra modi','artificial intelligence','coronavirus','pakistan']\n",
    "datasets=[]\n",
    "trainsets=[]\n",
    "for query in queries:\n",
    "    data=[] \n",
    "    training_X=[]\n",
    "    training_Y=[]\n",
    "    with open('data/'+query+'.csv', mode='r',encoding='utf-8') as sample:\n",
    "        sample_reader = csv.reader(sample, delimiter=',')\n",
    "        title=['rank']\n",
    "        for rank,row in enumerate(sample_reader):\n",
    "            if rank==0:\n",
    "                title=title+row\n",
    "                data=[[] for x in title]\n",
    "            else:\n",
    "                data[0].append(rank)\n",
    "                training_Y.append(rank)\n",
    "                for i in range(0,len(row)):\n",
    "                    data[i+1].append(row[i])\n",
    "                how_old=(datetime.now()-datetime.strptime(row[8], '%I:%M %p · %d %b %Y')).total_seconds()\n",
    "                cos=cosine(\" \".join(clean_tweets(row[7])),\" \".join(clean_tweets(row[1])))*100\n",
    "                jac=jaccard(\" \".join(clean_tweets(row[7])),\" \".join(clean_tweets(row[1])))*100\n",
    "                training_X.append([int(row[3]), int(row[4]), int(row[5]), int(row[6]), int(how_old), int(row[9]), int(row[10]), int(row[11]), int(row[12]), int(row[15]), int(row[16]), int(cos), int(jac)])\n",
    "    datasets.append(data)\n",
    "    trainsets.append([training_X,training_Y])\n",
    "    print(title) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessing.normalize(np.array(training_X))\n",
    "\n",
    "# y = np.array(training_Y)\n",
    "\n",
    "y = preprocessing.normalize(np.array(training_Y).reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsets=trainsetS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_trainsets=[]\n",
    "for trainset in trainsets:\n",
    "    normalized_trainsets.append([preprocessing.normalize(np.array(trainset[0])),preprocessing.normalize(np.array(trainset[1]).reshape(1, -1))[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 16/500 [00:00<00:03, 158.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dataset\n",
      "The number of data, train: 4038 validate: 213\n",
      "in resume\n",
      "prepare initialized model!\n",
      "[8.1775262e-08 8.6267388e-01 4.6448349e-05 4.1746272e-04 5.0576031e-01\n",
      " 0.0000000e+00 3.3527857e-04 5.2336168e-06 7.4415489e-06 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 116/500 [00:00<00:02, 155.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 100\n",
      "NDCG@100 | train: 0.54883390061994, test: 0.5054806044113558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 218/500 [00:01<00:02, 138.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 200\n",
      "NDCG@100 | train: 0.5755355420455632, test: 0.5149138551618868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 314/500 [00:01<00:01, 146.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 300\n",
      "NDCG@100 | train: 0.5443170645335996, test: 0.5064772120544331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 419/500 [00:02<00:00, 161.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 400\n",
      "NDCG@100 | train: 0.551922688934455, test: 0.5095823929060167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 171.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 500\n",
      "NDCG@100 | train: 0.5572350846705082, test: 0.5133365817907548\n",
      "save the model\n",
      "save the optimizer\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for trainset in normalized_trainsets[:1]:\n",
    "    rankNetModel.fit(trainset[0], trainset[1], batchsize=100, n_iter=500, n_units1=256, n_units2=32, tv_ratio=0.95, optimizerAlgorithm=\"Adam\", savefigName=\"result.pdf\", savemodelName=\"RankNet.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=rankNetModel.predict(normalized_trainsets[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ans:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
