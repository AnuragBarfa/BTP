{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf_upgrade_v2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-522c78eb6982>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf_upgrade_v2\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_ranking\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m_TRAIN_DATA_PATH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/data/train.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf_upgrade_v2' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr\n",
    "\n",
    "_TRAIN_DATA_PATH=\"/data/train.txt\"\n",
    "_TEST_DATA_PATH=\"/data/test.txt\"\n",
    "_LOSS=\"approx_ndcg_loss\"\n",
    "_N_ASSETS=100\n",
    "_N_FEATURES=16\n",
    "_BATCH_SIZE=32\n",
    "_HIDDEN_LAYER_DIMS=[\"20\", \"10\"]\n",
    "\n",
    "\n",
    "# Input Pipeline\n",
    "def input_fn(path):\n",
    "    data = tf.data.Dataset.from_generator(\n",
    "        tfr.data.libsvm_generator(path, _N_FEATURES, _N_ASSETS),\n",
    "        output_types=({str(k): tf.float32 for k in range(1,_N_FEATURES+1)}, tf.float32),\n",
    "        output_shapes=(\n",
    "            {str(k): tf.TensorShape([_N_ASSETS, 1]) for k in range(1,_N_FEATURES+1)},\n",
    "            tf.TensorShape([_N_ASSETS])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    data = data.shuffle(1000).repeat().batch(_BATCH_SIZE)\n",
    "  \n",
    "    return data.make_one_shot_iterator().get_next()\n",
    "\n",
    "\n",
    "def example_feature_columns():\n",
    "    \"\"\"Returns the example feature columns.\"\"\"\n",
    "    \n",
    "    feature_names = [\"%d\" % (i + 1) for i in range(0, _N_FEATURES)]\n",
    "    \n",
    "    return {name: tf.feature_column.numeric_column(name, shape=(1,), default_value=0.0)\n",
    "            for name in feature_names}\n",
    "\n",
    "\n",
    "# Scoring Function\n",
    "def make_score_fn():\n",
    "    \"\"\"Returns a scoring function to build `EstimatorSpec`.\"\"\"\n",
    "\n",
    "    def _score_fn(context_features, group_features, mode, params, config):\n",
    "        \"\"\"Defines the network to score assets.\"\"\"\n",
    "        \n",
    "        del params\n",
    "        del config\n",
    "        # Define input layer.\n",
    "        example_input = [\n",
    "            tf.layers.flatten(group_features[name])\n",
    "            for name in sorted(example_feature_columns())\n",
    "        ]\n",
    "        input_layer = tf.concat(example_input, 1)\n",
    "\n",
    "        cur_layer = input_layer\n",
    "        for i, layer_width in enumerate(int(d) for d in _HIDDEN_LAYER_DIMS):\n",
    "            cur_layer = tf.layers.dense(\n",
    "                cur_layer,\n",
    "                units=layer_width,\n",
    "                activation=\"tanh\")\n",
    "\n",
    "        logits = tf.layers.dense(cur_layer, units=1)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "    return _score_fn\n",
    "\n",
    "\n",
    "# Evaluation Metric\n",
    "def eval_metric_fns():\n",
    "    \"\"\"Returns a dict from name to metric functions.\n",
    "      Returns:\n",
    "        A dict mapping from metric name to a metric function with above signature.\n",
    "    \"\"\"\n",
    "      \n",
    "    metric_fns = {}\n",
    "    metric_fns.update({\n",
    "        \"metric/ndcg@%d\" % topn: tfr.metrics.make_ranking_metric_fn(\n",
    "            tfr.metrics.RankingMetricKey.NDCG, topn=topn)\n",
    "        for topn in [1, 3, 5, 10]\n",
    "    })\n",
    "    \n",
    "    return metric_fns\n",
    "\n",
    "\n",
    "# Estimator\n",
    "def get_estimator(hparams):\n",
    "    \"\"\"Create a ranking estimator.\n",
    "    Args:\n",
    "    hparams: (tf.contrib.training.HParams) a hyperparameters object.\n",
    "    Returns:\n",
    "    tf.learn `Estimator`.\n",
    "    \"\"\"\n",
    "    \n",
    "    def _train_op_fn(loss):\n",
    "        \"\"\"Defines train op used in ranking head.\"\"\"\n",
    "        return tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step(),\n",
    "            learning_rate=hparams.learning_rate,\n",
    "            optimizer=\"Adagrad\")\n",
    "\n",
    "    ranking_head = tfr.head.create_ranking_head(\n",
    "        loss_fn=tfr.losses.make_loss_fn(_LOSS),\n",
    "        eval_metric_fns=eval_metric_fns(),\n",
    "        train_op_fn=_train_op_fn)\n",
    "\n",
    "    return tf.estimator.Estimator(\n",
    "        model_fn=tfr.model.make_groupwise_ranking_fn(\n",
    "          group_score_fn=make_score_fn(),\n",
    "          group_size=1,\n",
    "          transform_fn=None,\n",
    "          ranking_head=ranking_head),\n",
    "        params=hparams)\n",
    "\n",
    "\n",
    "# Initialize estimator\n",
    "hparams = tf.contrib.training.HParams(learning_rate=0.05)\n",
    "ranker = get_estimator(hparams)\n",
    "\n",
    "# Train model\n",
    "ranker.train(input_fn=lambda: input_fn(_TRAIN_DATA_PATH), steps=100)\n",
    "\n",
    "# Evaluate model\n",
    "ranker.evaluate(input_fn=lambda: input_fn(_TEST_DATA_PATH), steps=100)\n",
    "\n",
    "# Visualize\n",
    "ranker.model_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
