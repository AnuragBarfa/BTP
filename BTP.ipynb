{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, math\n",
    "from collections import Counter\n",
    "\n",
    "WORD = re.compile(r'\\w+')\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "     intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "     numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "     sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "     sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "     denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "     if not denominator:\n",
    "        return 0.0\n",
    "     else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def text_to_vector(text):\n",
    "     words = WORD.findall(text)\n",
    "     return Counter(words)\n",
    "\n",
    "text1 = 'This is a foo bar sentence .'\n",
    "text2 = 'This sentence is similar to a foo bar sentence .'\n",
    "\n",
    "vector1 = text_to_vector(text1)\n",
    "vector2 = text_to_vector(text2)\n",
    "\n",
    "cosine = get_cosine(vector1, vector2)\n",
    "\n",
    "print('Cosine:', cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tweepy as tw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-twitter --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = twitter.Api(consumer_key='5QUCmsZc97JKVhSW7UqB4PmGO',\n",
    "                      consumer_secret='Szv1qILgFywnl1IbLakJDIqbt44unJOXWEWY7iZ2ksw6WZvDjx',\n",
    "                      access_token_key='1159073576495923200-s1eAfxDF86zf9J7brJoe2CEFwU0UW0',\n",
    "                      access_token_secret='sxA356gk2uPJFU5iIyoB2yKLUrAbnvZpSGV9cRtqzEWb7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users = api.GetFriends()\n",
    "print([u.name for u in users])\n",
    "timel=api.GetHomeTimeline()\n",
    "tie2=api.GetUserTimeline(screen_name=\"MMitanshu\")\n",
    "for ti in tie2:\n",
    "    print(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = api.GetSearch(\n",
    "    raw_query=\"q=twitter%20&result_type=recent&since=2014-07-19&count=100\")\n",
    "for res in results:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = api.GetSearch(raw_query=\"q=shiny pants&result_type=recent&since=2014-07-19\",result_type='mixed')\n",
    "for res in results:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "url = 'https://twitter.com/search?q=shiny%20pants&src=typed_query'\n",
    "response = get(url)\n",
    "print(response.text)\n",
    "from bs4 import BeautifulSoup\n",
    "html_soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movie_containers = html_soup.find_all('div')\n",
    "print(type(movie_containers))\n",
    "print(len(movie_containers))\n",
    "for m in movie_containers:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U selenium --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweet_mode used to get full text inplace of truncated\n",
    "results = api.GetSearch(\n",
    "    raw_query=\"q=holi%20&tweet_mode=extended\",include_entities=True,result_type='recent')\n",
    "for res in results:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "#from selenium.common.exceptions import TimeOutException, NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# path where the selenium driver is copied.\n",
    "#for lab pc ashish\n",
    "#driver_path = '/home/ashishranjan/chromedriver'\n",
    "#for home pc ashish\n",
    "# driver_path = '/home/ashish/Downloads/chromedriver'\n",
    "#for lab pc anurag\n",
    "# driver_path = '/home/anurag.barfa/mywork/btp/chromedriver'\n",
    "#for home pc anurag\n",
    "driver_path = '/home/anurag/Work/BTP/chromedriver'\n",
    "# This will open a new chrome session.\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"--disable-notifications\")\n",
    "driver = webdriver.Chrome(executable_path = driver_path,options=chrome_options)\n",
    "#driver.get(\"https://twitter.com/search?q=delhi%20election&src=typed_query\")\n",
    "query=\"pakistan\"\n",
    "driver.get(\"https://twitter.com/search?q=\"+query+\"&src=typed_query\")\n",
    "\n",
    "SCROLL_PAUSE_TIME = 10\n",
    "\n",
    "# Get scroll height\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "scroll_count=3 #number of times you want to scroll the page\n",
    "tweet_boxes=[]\n",
    "while True:\n",
    "    # Scroll down to bottom\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Wait to load page\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "    tutorial_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    tutorial_code_soup = tutorial_soup.find_all('div',attrs={'class':'css-1dbjc4n r-18u37iz r-thb0q2'})\n",
    "    tweet = tutorial_soup.find_all('div',{'class':'css-1dbjc4n r-1iusvr4 r-16y2uox r-1777fci r-5f2r5o r-1mi0q7o'})\n",
    "    tweet_boxes=tweet_boxes+tweet\n",
    "    scroll_count=scroll_count-1\n",
    "    if scroll_count==0:\n",
    "        break\n",
    "            \n",
    "#tutorial_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "# tutorial_code_soup1 = tutorial_soup.find_all('div',attrs={'class':'css-1dbjc4n r-18u37iz r-thb0q2'})\n",
    "# for tweet in tutorial_code_soup1:\n",
    "#     print(tweet)\n",
    "# # tutorial_code_soup2 = tutorial_soup.find_all('ol',attrs={'id':'stream-items-id'})\n",
    "# tutorial_code_soup2 = tutorial_soup.find_all('li',attrs={'class':'js-stream-item stream-item stream-item'})\n",
    "# for tweet in tutorial_code_soup2:\n",
    "#     print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetstemp=[]\n",
    " \n",
    "for i in tweet_boxes:\n",
    "    # Add to the new list\n",
    "    # only if not present\n",
    "    if i not in tweetstemp:\n",
    "        tweetstemp.append(i)\n",
    "tweet_boxes = tweetstemp\n",
    "len(tweet_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re, math\n",
    "from collections import Counter\n",
    "\n",
    "WORD = re.compile(r'\\w+')\n",
    "\n",
    "def text_to_vector(text):\n",
    "     words = WORD.findall(text)\n",
    "     return Counter(words)\n",
    "\n",
    "def cosine(tweet,query):\n",
    "    vec1 = text_to_vector(tweet.lower())\n",
    "    vec2 = text_to_vector(query.lower())\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "#     print(intersection)\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def jaccard(tweet,query):\n",
    "    vec1 = text_to_vector(tweet.lower())\n",
    "    vec2 = text_to_vector(query.lower())\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    union =set(vec1.keys()) | set(vec2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettweet(box,query):\n",
    "    tweet=box.findChildren('div',recursive=False)[1].text\n",
    "    user=box.findChildren('div',recursive=False)[0].findChildren('div',recursive=False)[0].findChildren('div',recursive=False)[0].findChildren(recursive=False)[0].text\n",
    "    date=box.findChildren('div',recursive=False)[0].findChildren('div',recursive=False)[0].findChildren('div',recursive=False)[0].findChildren(recursive=False)[2].attrs['title']\n",
    "    likes = comments = retweet = 'None'\n",
    "    span = box.find_all('div',{'class':'css-901oao r-1awozwy r-1re7ezh r-6koalj r-1qd0xha r-a023e6 r-16dba41 r-1h0z5md r-ad9z0x r-bcqeeo r-o7ynqc r-clp7b1 r-3s2u2q r-qvutc0'})\n",
    "    likes = span[3].text\n",
    "    retweet = span[2].text\n",
    "    comments = span[1].text\n",
    "    tags=[]\n",
    "    mentions=[]\n",
    "    urls=0\n",
    "    for anchor in box.find_all('a'):\n",
    "        #print(anchor.text+\"######\")\n",
    "        if 'href' in anchor.attrs:\n",
    "            if anchor.attrs['href'].split('/')[1]=='hashtag':\n",
    "                tags.append(anchor.text)\n",
    "            if anchor.attrs['href'].split(':')[0]=='https':\n",
    "                urls=urls+1\n",
    "        if len(anchor.text)>0 and anchor.text[0]=='@':\n",
    "            mentions.append(anchor.text)\n",
    "        \n",
    "    #print(tags)\n",
    "    #print(mentions)\n",
    "    cosine_similarity=cosine(tweet,query)*100\n",
    "    multimedia_flag=0\n",
    "    s = str(box.find('img'))\n",
    "    if ((box.find('img') and s.find('format')!=-1 )  or box.find('video')):\n",
    "        multimedia_flag=1  \n",
    "    return tweet,likes,comments,retweet,user,date,tags,mentions,multimedia_flag,urls,cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('data/sample_pakistan.csv', mode='w') as sample:\n",
    "    sample_writer = csv.writer(sample, delimiter=',')\n",
    "    sample_writer.writerow(['Query','Date','user','Tweet','Img_present','Likes','commnets','retweet','tags','mentions','url_count','length','cosine_similarity(%)'])\n",
    "    for boxes in tweet_boxes:\n",
    "        tweet,likes,comments,retweet,user,date,tags,mentions,multimedia_flag,urls,cosine_similarity = gettweet(boxes,query)\n",
    "        sample_writer.writerow([query,date, user, tweet, multimedia_flag,likes,comments,retweet,\",\".join(tags),\",\".join(mentions),urls,len(tweet),cosine_similarity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tutorial_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "#tweet_boxes = tutorial_soup.find_all('div',attrs={'class':'css-1dbjc4n r-18u37iz r-thb0q2','data-testid':'tweet'})\n",
    "tweet_boxes = tutorial_soup.find_all('div',{'class':'css-1dbjc4n r-1iusvr4 r-16y2uox r-1777fci r-5f2r5o r-1mi0q7o'})\n",
    "len(tweet_boxes)\n",
    "tweet_boxes[1].findChildren('div',recursive=False)[3].attrs.get('aria-label')\n",
    "for i in range(0,len(tweet_boxes)):\n",
    "    print(tweet_boxes[i].findChildren('div',recursive=False)[3].attrs.get('aria-label'))\n",
    "#     tweet_boxes[i].findChildren('div',recursive=False)[3].attrs.get('aria-label')\n",
    "box = tweet_boxes[2]\n",
    "#small_boxes = box.find_all('div',{'class':'css-901oao r-hkyrab r-1qd0xha r-a023e6 r-16dba41 r-ad9z0x r-bcqeeo r-bnwqim r-qvutc0','lang':'en'})\n",
    "if(box.find('img')):\n",
    "    small_boxes = box.find('img')\n",
    "    print(small_boxes)\n",
    "boxes = tweet_boxes[2]\n",
    "#boxes.text\n",
    "#span = boxes.find_all('span',{'class':'css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0'})\n",
    "span = boxes.find_all('div',{'class':'css-901oao r-1awozwy r-1re7ezh r-6koalj r-1qd0xha r-a023e6 r-16dba41 r-1h0z5md r-ad9z0x r-bcqeeo r-o7ynqc r-clp7b1 r-3s2u2q r-qvutc0'})\n",
    "span[4].text\n",
    "#span[len(span)-1].text.isdigit()<div dir=\"ltr\" class=\"\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
