{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for data handling\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file is in letor dataset format\n",
    "#converting data from standard format(data of all queries should be together) \n",
    "data=pd.read_csv(\"MyFile8.txt\",sep=\" \", header=None)\n",
    "datasets={}\n",
    "qid='qid:-1'\n",
    "counter=0\n",
    "for row in data.values:\n",
    "  if qid!=row[1]:\n",
    "    counter=0\n",
    "  counter=counter+1\n",
    "  qid=row[1]\n",
    "#   print(row)\n",
    "  l=len(row)\n",
    "  row_data=[row[l-1]]\n",
    "  for i in row[2:l-3]:\n",
    "    # print(i)\n",
    "    row_data.append(float(i.split(\":\")[1]))\n",
    "  x_df = pd.DataFrame([row_data],columns=['doc_id','verified', 'Img_present', 'url_bool',\n",
    "       'hashtag_bool', 'followers_count', 'friends_count', 'listed_count',\n",
    "       'likes', 'comments', 'retweets', 'sum_followers_mention', 'url_count',\n",
    "       'how_old', 'cosine', 'jaccard', 'hashtag_count', 'dice', 'word_count',\n",
    "       'char_count', 'follower_friend_relation', 'tfidf_similarity', 'okapi'])\n",
    "  y_df = pd.DataFrame([[float(row[0]),counter]],columns=['label','score'])\n",
    "  if qid in datasets.keys():\n",
    "    datasets[qid]['X']=pd.concat([datasets[qid]['X'], x_df], ignore_index=True)\n",
    "    datasets[qid]['Y']=pd.concat([datasets[qid]['Y'], y_df], ignore_index=True)\n",
    "  else:\n",
    "    datasets[qid]={'X':x_df,'Y':y_df}\n",
    "for key in datasets.keys():\n",
    "  curr_df=datasets[key]['Y']['score']\n",
    "  maxi=curr_df.max()\n",
    "  mini=curr_df.min()\n",
    "  datasets[key]['Y']['score']=[(maxi-score)/(maxi-mini) for score in curr_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_numerical_feature=pd.DataFrame([])\n",
    "combined_data_categorical_feature=pd.DataFrame([])\n",
    "combined_data_output=pd.DataFrame([])\n",
    "for key in datasets.keys():\n",
    "  curr_cate=datasets[key]['X'][['verified', 'Img_present', 'url_bool','hashtag_bool']]\n",
    "  curr_nume=datasets[key]['X'][['followers_count', 'friends_count', 'listed_count',\n",
    "       'likes', 'comments', 'retweets', 'sum_followers_mention', 'url_count',\n",
    "       'how_old', 'cosine', 'jaccard', 'hashtag_count', 'dice', 'word_count',\n",
    "       'char_count', 'follower_friend_relation', 'tfidf_similarity', 'okapi']]\n",
    "  curr_output=datasets[key]['Y']\n",
    "  if combined_data_numerical_feature.empty:\n",
    "    combined_data_numerical_feature=curr_nume\n",
    "    combined_data_categorical_feature=curr_cate\n",
    "    combined_data_output=curr_output\n",
    "  else:\n",
    "    combined_data_numerical_feature=pd.concat([combined_data_numerical_feature, curr_nume], ignore_index=True)\n",
    "    combined_data_categorical_feature=pd.concat([combined_data_categorical_feature, curr_cate], ignore_index=True)\n",
    "    combined_data_output=pd.concat([combined_data_output, curr_output], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression,f_classif,chi2\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def filterBasedFeatureSelection(filter_type,X, y, X_type, y_type, top_k=None):\n",
    "  #this function print the score for top_k features and return the list of top_k features is deacreasing order\n",
    "  if top_k==None:\n",
    "    top_k=X.shape[1]\n",
    "  if filter_type=='Univariate Selection':\n",
    "    # Filter based-1. Univariate Selection\n",
    "    if X_type=='num' and y_type=='num':\n",
    "      score_function=f_regression\n",
    "    elif X_type=='num' and y_type=='cat':\n",
    "      score_function=f_classif\n",
    "    elif X_type=='cat' and y_type=='cat':\n",
    "      score_function=chi2\n",
    "    else:\n",
    "      print(\"type or combination mentioned is not allowed\")\n",
    "      return\n",
    "    bestfeatures = SelectKBest(score_func=score_function, k=top_k)\n",
    "    fit = bestfeatures.fit(X, y)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    #concat two dataframes for better visualization \n",
    "    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "    top_k_feature_metric=featureScores.nlargest(top_k,'Score')\n",
    "    print(top_k_feature_metric)\n",
    "    return list(top_k_feature_metric['Specs'].values) \n",
    "  elif filter_type=='Feature Importance':\n",
    "    model = ExtraTreesClassifier()\n",
    "    model.fit(X,y)\n",
    "    # print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "    #plot graph of feature importances for better visualization\n",
    "    feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "    print(feat_importances.nlargest(10))\n",
    "    feat_importances.nlargest(10).plot(kind='barh')\n",
    "    # plt.show()\n",
    "    plt.savefig(\"featImportance.png\")\n",
    "    return list(feat_importances.nlargest(10).to_frame().index)\n",
    "  elif filter_type=='Correlation Matrix':\n",
    "    # Filter based-3. Correlation Matrix with Heatmap\n",
    "    data=pd.concat([X,y],axis=1)\n",
    "    corrmat = data.corr()#get correlations of each features in dataset\n",
    "    top_corr_features = corrmat.index\n",
    "    plt.figure(figsize=(20,20))\n",
    "    #plot heat map\n",
    "    g=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n",
    "    plt.savefig(\"heatMap.png\")\n",
    "    print(corrmat['score'][corrmat['score'].abs().nlargest(top_k).index][1:])\n",
    "    return list(corrmat['score'].abs().nlargest(top_k)[1:].index)\n",
    "    # return corrmat\n",
    "  else:\n",
    "    print(\"no such filter based method available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0\n",
    "b=50\n",
    "filterBasedFeatureSelection('Univariate Selection',combined_data_numerical_feature[a:b], combined_data_output['score'][a:b],'num','num')\n",
    "# filterBasedFeatureSelection('Univariate Selection',combined_data_numerical_feature, combined_data_output['label'],'num','cat',11)\n",
    "# filterBasedFeatureSelection('Univariate Selection',combined_data_categorical_feature, combined_data_output['label'],'cat','cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=150\n",
    "b=3000\n",
    "X=filterBasedFeatureSelection('Correlation Matrix',combined_data_numerical_feature[a:b], combined_data_output['score'][a:b],'num','num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/@aneesha/recursive-feature-elimination-with-scikit-learn-3a2cbdf23fb7\n",
    "#Wrapper-based-Recursive Feature Elimination\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import RFE\n",
    "# create the RFE model for the svm classifier and select attributes\n",
    "rfe_selector = RFE(estimator=LinearSVC(), n_features_to_select=3)\n",
    "rfe_selector = rfe_selector.fit(combined_data_categorical_feature, combined_data_output['label'])\n",
    "\n",
    "rfe_selector1 = RFE(estimator=LinearSVC(), n_features_to_select=18)\n",
    "rfe_selector1 = rfe_selector1.fit(combined_data_numerical_feature, combined_data_output['label'])\n",
    "\n",
    "# print summaries for the selection of attributes\n",
    "print(combined_data_numerical_feature.columns)\n",
    "print(rfe_selector1.support_)\n",
    "print(rfe_selector1.ranking_)\n",
    "\n",
    "print(combined_data_categorical_feature.columns)\n",
    "print(rfe_selector.support_)\n",
    "print(rfe_selector.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=rfe_selector1.ranking_\n",
    "y=list(combined_data_numerical_feature.columns)\n",
    "dic={}\n",
    "for i in range(0,len(x)):\n",
    "  dic[x[i]]=y[i]\n",
    "dic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
